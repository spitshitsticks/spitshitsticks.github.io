---
layout: post
title:  "Что такое аналитические БД и зачем они нужны?"
author: "Evgeniy Petrov"
tags: ["аналитика", "clickhouse"]
---

Было обычное барселонское утро.

> У Сотрудника1 просели пуши последние 3 месяца, хотя объем трафика не падает.

Сообщение сопровождалось скриншотом, на котором было видно, что доходы действительно падают,
несмотря на сохранное количество подписок.

Это сообщение меня не обрадовало, поскольку я хорошо знал, что данные по рассылкам хранятся
в очень неудобном виде, и найти в них что-то крайне затруднительно.

Процесс дата-майнинга, в общем случае, заключается в том, что мы выдвигаем гипотезы на
основании имеющихся знаний и затем проверяем их. Для успешной проверки гипотез вам необходима
аналитическая база данных. Является ли ваш MySQL, PostgreSQL или MongoDB аналитической БД?
Скорее всего, нет, и вот почему.

## Производительность

Когда вы работаете с данными, вы выдвигаете десятки гипотез. Если на проверку одной гипотезы
уходит неделя, то через неделю вы просто забудете, что делали, и, даю руку на отсечение,
заниматься этим вы не будете. Аналитическая БД должна быть быстрой.

Например, я проверял гипотезу о том, что у разных сотрудников одни и те же пользователи получают
одинаковые сообщения и в итоге кликают только на одно. Но проблема в том, что в данных нет
идентификатора, по которому можно было бы определить, что два разных пользователя в базе
данных — это один и тот же человек. Мне пришлось создать некое подобие fingerprint на основе
имеющихся данных (хэш от локации, ISP, часового пояса, языка браузера и других данных). После
этого получилось исключить из анализа пользователей с одинаковым отпечатком и убедиться, что
проблема остается на других пользователях. Так была исключена гипотеза.

По сути, проверка гипотезы свелась к добавлению одной колонки и JOIN-запроса:
```sql
ALTER TABLE push
    ADD COLUMN _fingerprint String MATERIALIZED MD5(<fingerprint fields, …>);
```

```sql
SELECT
    <dimensions>,
    <measures>
FROM push
INNER JOIN (
    SELECT _fingerprint
    FROM push
    WHERE type = 'subscription'
    GROUP BY ALL
    HAVING count() = 1
) AS _ ON _._fingerprint = push._fingerprint
WHERE <filters>
GROUP BY ALL
```

При наличии нескольких десятков миллионов подписок эти запросы в MySQL выполнялись бы вечно.
Правильная аналитическая БД выполняет их за минуты или даже секунды.

## Средства визуализации

У вас должна быть возможность создавать различные графики, тепловые карты, гистограммы и пр.
Вы должны видеть свои данные визуально. Посмотрите на пример. Видите ли вы аномалию, глядя только
на цифры? А теперь посмотрите на график (нужно повернуть голову вправо).
```
┌─────foo─┬─bar─────────────────────┐
│     981 │ █████████████████████▊  │
│  1002.9 │ ██████████████████████▎ │
│ 1002.24 │ ██████████████████████▎ │
│  987.03 │ █████████████████████▉  │
│  974.55 │ █████████████████████▌  │
│  981.97 │ █████████████████████▊  │
│  974.05 │ █████████████████████▌  │
│ 1000.33 │ ██████████████████████▎ │
│   970.5 │ █████████████████████▍  │
│  962.23 │ █████████████████████▏  │
│  976.76 │ █████████████████████▋  │
│  997.14 │ ██████████████████████▏ │
│  992.81 │ ██████████████████████  │
│  997.68 │ ██████████████████████▏ │
│  973.02 │ █████████████████████▌  │
│  983.77 │ █████████████████████▊  │
│  902.05 │ ███████████████████▌    │
│  902.19 │ ███████████████████▌    │
│  887.96 │ ███████████████████▏    │
│  891.41 │ ███████████████████▎    │
└─────────┴─────────────────────────┘
```

И хотя визуализация, как правило, это не задача базы данных, аналитическая БД должна быть легко подключаема к BI инструментам.

## Простое подключение внешних данных

Отлично, если в базе уже есть все нужные данные. Но что, если чего-то не хватает? Например, у вас
есть идентификатор кампании, но вам нужно знать источник трафика, который есть только в админке в
формате CSV. Или вам нужны курсы валют, доступные через API в формате JSON. Или у вас есть IP-адрес,
а вам нужно получить по нему страну и провайдера. Если вы занимаетесь анализом данных, такие задачи
должны решаться 10-20 строками кода на вашем любимом языке программирования.

```sql
CREATE TABLE monobank_currency
(
    `date` DateTime,
    `buying` Decimal(18, 4),
    `selling` Decimal(18, 4)
)
ENGINE = URL('https://kurstoday.com.ua/api/chart?exchanger_id=50&currency=EUR&from=2022-01&to=2024-12', 'JSON')
```

```sql
SELECT *
FROM monobank_currency
ORDER BY date DESC
LIMIT 10
```
```
┌────────────────date─┬─buying─┬─selling─┐
│ 2024-05-11 00:00:00 │  42.45 │   43.09 │
│ 2024-05-10 00:00:00 │  42.45 │   43.15 │
│ 2024-05-09 00:00:00 │  42.29 │   42.91 │
│ 2024-05-08 00:00:00 │   42.1 │   42.71 │
│ 2024-05-07 00:00:00 │  42.18 │   42.71 │
│ 2024-05-06 00:00:00 │  42.22 │   42.89 │
│ 2024-05-05 00:00:00 │   42.3 │    42.9 │
│ 2024-05-04 00:00:00 │   42.3 │    42.9 │
│ 2024-05-03 00:00:00 │   42.3 │    42.9 │
│ 2024-05-02 00:00:00 │  42.25 │   42.73 │
└─────────────────────┴────────┴─────────┘
```

## Удобство работы

Я долгое время любил Elasticsearch за его скорость. Но он абсолютно не годится для анализа данных, потому
что не поддерживает SQL (на самом деле теперь частично поддерживает, но поезд уже ушел). Писать запросы на
JSON крайне неудобно. По этой же причине MongoDB не подходит для аналитики.

## Ну а что там с пушами?

Подготовка данных к анализу заняла две недели. Затем, проанализировав метрики на каждом этапе воронки,
я быстро понял, что пользователи плохо кликают на сообщения, поэтому сосредоточился на анализе CTR.
После этого я начал проверку гипотез.

В чем суть? У нас есть два набора данных: в одном высокий CTR, в другом низкий. Мы предполагаем, например,
что в первом наборе данных больше пользователей из страны X, чем во втором, и что в этой стране по
какой-то причине выше CTR. Разбиваем CTR по странам в обоих наборах данных и видим, что он не зависит
от страны. Поскольку влияние страны исключено, для достоверности выбираем страну с большим количеством
данных в обеих группах и сосредотачиваемся только на ней. Затем выдвигаем новую гипотезу и повторяем все
шаги, пока не увидим четкую зависимость между каким-то фактором и CTR. 

```
┌─TrafficSource─┬─Clicks─┬─Mailings─┬─ClickRatio─┐
│ source1       │    462 │    26591 │       1.74 │
│ source2       │    212 │    18959 │       1.12 │
│ source3       │    659 │     5775 │      11.41 │
│ source4       │     52 │     5761 │        0.9 │
│ source5       │    415 │     2475 │      16.77 │
│ source6       │     16 │      270 │       5.93 │
└───────────────┴────────┴──────────┴────────────┘
```

Америку я не открыл: трафик с источников, которые сами рассылают сообщения, имеет низкий CTR. Для
надежности еще раз проверяем начальную проблему и выясняем, что действительно за последние три месяца
доля трафика из источника с низким CTR увеличилась, что и привело к падению доходов с рассылок.

## Вывод

Таким образом, с прямыми руками и правильными инструментами аналитика данных становится гораздо проще.
Эффективная аналитическая база данных позволяет обнаруживать скрытые закономерности, принимать
обоснованные решения и настраивать бизнес на устойчивый рост.