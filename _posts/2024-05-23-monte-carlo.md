Предположим, мы продаем трафик на продукт, который платит $8 за какое-то действие пользователя. Нам выгодно слать на этот продукт, только если конечный EPC (earning per click) будет больше либо равен $0.33. Спустя какое-то время после запуска мы видим следующие результаты:

| Clicks | Conversions |   Revenue |   CTR |   EPC |
|-------:|------------:|----------:|------:|------:|
|    235 |           7 |    $56.00 | 2.98% | $0.24 |

Внимание, вопрос: стоит ли нам продолжать трафик на этот продукт?

Опытные, вероятно, заметили, что данных на самом деле не очень много, и, вероятно, надо еще подождать. А сколько подождать? Если ждать мало, то потенциально мы можем упустить хороший источник трафика. Если ждать долго, то мы можем потерять лишние деньги.

Давайте считать. В статистике существует такой важный термин, как **статистическая значимость**. Она позволяет нам понять не просто больше ли одно значение, чем другое, а еще и насколько мы можем быть в этом уверены.

Предположим, что на самом деле реальный EPC у нашего продукта не $0.24, а $0.33 либо даже больше, а то, что мы видим меньшие цифры — это просто случайность, такая же как и длинные серии из орлов и решек. Давайте посчитаем вероятность того, что при EPC равном $0.33, мы случайным образом  получили бы именно такие результаты, какие мы видим или даже хуже.

Поскольку мы тут программисты, а не математики, давайте вместо формул просто напишем симуляцию эксперимента, в котором 235 кликов будут генерировать конверсии таким образом, чтобы получился нужный нам EPC в $0.33. Мы проведем эксперимент очень много раз, а потом посчитаем, в каком количестве экспериментов мы получили результаты хуже либо такие же, как в постановке задачи. Это и будет наша вероятность (этот метод, кстати, называется метод Монте-Карло).

Для простоты я перейду от EPC к CTR. Для того чтобы у нас был EPC в $0.33, нам нужно, чтобы CTR был равен 4.12%:

```python
import numpy as np

clicks = 235
conversions = 7
hypothesized_rate = 0.0412
num_simulations = 100000

simulated_conversions = np.random.binomial(
    clicks,
    hypothesized_rate,
    num_simulations,
)
```

Теперь посмотрим на распределение количества конверсий в наших симуляциях:
```python
import matplotlib.pyplot as plt

plt.hist(simulated_conversions, bins=27)
plt.axvline(x=conversions, color='red', linestyle='--')
plt.xlabel('Number of conversions')
plt.ylabel('Number of experiments')
plt.show()
```

![](/assets/monte-carlo-1.png)

Мы видим, что количество конверсий, равное 7 (как в изначальных данных) либо меньше, выпадает достаточно часто. А если быть точнее, в 24.48% случаев:

```python
np.mean(simulated_conversions <= conversions)
```

То есть, другими словами, при реальном EPC в $0.33, если мы будем предполагать, основываясь на имеющихся данных, что EPC у нашего продукта все-таки $0.24, мы будем ошибаться в 24.48% случаев. Много ли это? Это много, это значит, что каждую пятую кампанию вы будете тратить деньги неэффективно. У аналитиков, как правило, принято ошибаться не чаще чем в 5% случаев.

Хорошо, а сколько данных нам нужно, чтобы ошибаться в 5%?

Мы можем проделать все то же самое для разного количества кликов и посмотреть, в какой момент ошибка опустится до приемлемого уровня.

```python
x = []
y = []

observed_ctr = 0.0298
for clicks in range(10, 2000, 10):
    conversions = int(np.round(clicks * observed_ctr))
    x.append(clicks)
    y.append(simulate(clicks, conversions))

plt.plot(x, y)
plt.axhline(y=0.05, color='r', linestyle='--')
plt.xlabel('Number of clicks')
plt.ylabel('Probability of error')
plt.show()
```
![](/assets/monte-carlo-2.png)

На графике видно, что при примерно 830 кликах вероятность получить наблюдаемые данные (EPC $0.24), при условии, что в реальности EPC равен $0.33, будет уже примерно 5%. И если вы все-таки получите в результате EPC $0.24, тогда уже можно с высокой достоверностью (а именно 95%) утверждать, что кампанию стоит остановить.

#аналитика